{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2: predicting data_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter('ignore',DeprecationWarning)\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import confusion_matrix as conf\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../data/'\n",
    "data_file = 'OnlineNewsPopularity.csv'\n",
    "\n",
    "file_2_read = data_dir + data_file\n",
    "df = pd.read_csv(file_2_read)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['url',\n",
       " 'timedelta',\n",
       " 'n_tokens_title',\n",
       " 'n_tokens_content',\n",
       " 'n_unique_tokens',\n",
       " 'n_non_stop_words',\n",
       " 'n_non_stop_unique_tokens',\n",
       " 'num_hrefs',\n",
       " 'num_self_hrefs',\n",
       " 'num_imgs',\n",
       " 'num_videos',\n",
       " 'average_token_length',\n",
       " 'num_keywords',\n",
       " 'data_channel_is_lifestyle',\n",
       " 'data_channel_is_entertainment',\n",
       " 'data_channel_is_bus',\n",
       " 'data_channel_is_socmed',\n",
       " 'data_channel_is_tech',\n",
       " 'data_channel_is_world',\n",
       " 'kw_min_min',\n",
       " 'kw_max_min',\n",
       " 'kw_avg_min',\n",
       " 'kw_min_max',\n",
       " 'kw_max_max',\n",
       " 'kw_avg_max',\n",
       " 'kw_min_avg',\n",
       " 'kw_max_avg',\n",
       " 'kw_avg_avg',\n",
       " 'self_reference_min_shares',\n",
       " 'self_reference_max_shares',\n",
       " 'self_reference_avg_sharess',\n",
       " 'weekday_is_monday',\n",
       " 'weekday_is_tuesday',\n",
       " 'weekday_is_wednesday',\n",
       " 'weekday_is_thursday',\n",
       " 'weekday_is_friday',\n",
       " 'weekday_is_saturday',\n",
       " 'weekday_is_sunday',\n",
       " 'is_weekend',\n",
       " 'LDA_00',\n",
       " 'LDA_01',\n",
       " 'LDA_02',\n",
       " 'LDA_03',\n",
       " 'LDA_04',\n",
       " 'global_subjectivity',\n",
       " 'global_sentiment_polarity',\n",
       " 'global_rate_positive_words',\n",
       " 'global_rate_negative_words',\n",
       " 'rate_positive_words',\n",
       " 'rate_negative_words',\n",
       " 'avg_positive_polarity',\n",
       " 'min_positive_polarity',\n",
       " 'max_positive_polarity',\n",
       " 'avg_negative_polarity',\n",
       " 'min_negative_polarity',\n",
       " 'max_negative_polarity',\n",
       " 'title_subjectivity',\n",
       " 'title_sentiment_polarity',\n",
       " 'abs_title_subjectivity',\n",
       " 'abs_title_sentiment_polarity',\n",
       " 'shares']"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "col_names = df.columns.values.tolist()\n",
    "\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['n_non_stop_words']\n",
    "del df['n_non_stop_unique_tokens']\n",
    "del df['n_unique_tokens']\n",
    "del df['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>timedelta</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>354.530471</td>\n",
       "      <td>214.163767</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>542.000000</td>\n",
       "      <td>731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_tokens_title</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>10.398749</td>\n",
       "      <td>2.114037</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_tokens_content</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>546.514731</td>\n",
       "      <td>471.107508</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>716.000000</td>\n",
       "      <td>8474.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_hrefs</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>10.883690</td>\n",
       "      <td>11.332017</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>304.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>3.293638</td>\n",
       "      <td>3.855141</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>116.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_imgs</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>4.544143</td>\n",
       "      <td>8.309434</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_videos</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>1.249874</td>\n",
       "      <td>4.107855</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_token_length</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>4.548239</td>\n",
       "      <td>0.844406</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.478404</td>\n",
       "      <td>4.664082</td>\n",
       "      <td>4.854839</td>\n",
       "      <td>8.041534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_keywords</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>7.223767</td>\n",
       "      <td>1.909130</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.052946</td>\n",
       "      <td>0.223929</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.178009</td>\n",
       "      <td>0.382525</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.157855</td>\n",
       "      <td>0.364610</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.058597</td>\n",
       "      <td>0.234871</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.185299</td>\n",
       "      <td>0.388545</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.212567</td>\n",
       "      <td>0.409129</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_min</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>26.106801</td>\n",
       "      <td>69.633215</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>377.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_max_min</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>1153.951682</td>\n",
       "      <td>3857.990877</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>445.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>298400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_avg_min</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>312.366967</td>\n",
       "      <td>620.783887</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>141.750000</td>\n",
       "      <td>235.500000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>42827.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_max</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>13612.354102</td>\n",
       "      <td>57986.029357</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>7900.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_max_max</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>752324.066694</td>\n",
       "      <td>214502.129573</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_avg_max</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>259281.938083</td>\n",
       "      <td>135102.247285</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>172846.875000</td>\n",
       "      <td>244572.222223</td>\n",
       "      <td>330980.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_avg</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>1117.146610</td>\n",
       "      <td>1137.456951</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1023.635611</td>\n",
       "      <td>2056.781032</td>\n",
       "      <td>3613.039820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_max_avg</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>5657.211151</td>\n",
       "      <td>6098.871957</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3562.101631</td>\n",
       "      <td>4355.688836</td>\n",
       "      <td>6019.953968</td>\n",
       "      <td>298400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>3135.858639</td>\n",
       "      <td>1318.150397</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2382.448566</td>\n",
       "      <td>2870.074878</td>\n",
       "      <td>3600.229564</td>\n",
       "      <td>43567.659946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>3998.755396</td>\n",
       "      <td>19738.670516</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>639.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>2600.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>10329.212662</td>\n",
       "      <td>41027.576613</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>2800.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>6401.697580</td>\n",
       "      <td>24211.332231</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>981.187500</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>5200.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.168020</td>\n",
       "      <td>0.373889</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.186409</td>\n",
       "      <td>0.389441</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.187544</td>\n",
       "      <td>0.390353</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.183306</td>\n",
       "      <td>0.386922</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.143805</td>\n",
       "      <td>0.350896</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.061876</td>\n",
       "      <td>0.240933</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.069039</td>\n",
       "      <td>0.253524</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_weekend</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.130915</td>\n",
       "      <td>0.337312</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_00</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.184599</td>\n",
       "      <td>0.262975</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.025051</td>\n",
       "      <td>0.033387</td>\n",
       "      <td>0.240958</td>\n",
       "      <td>0.926994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_01</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.141256</td>\n",
       "      <td>0.219707</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.025012</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>0.150831</td>\n",
       "      <td>0.925947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_02</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.216321</td>\n",
       "      <td>0.282145</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.334218</td>\n",
       "      <td>0.919999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_03</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.223770</td>\n",
       "      <td>0.295191</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.375763</td>\n",
       "      <td>0.926534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_04</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.234029</td>\n",
       "      <td>0.289183</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.040727</td>\n",
       "      <td>0.399986</td>\n",
       "      <td>0.927191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_subjectivity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.443370</td>\n",
       "      <td>0.116685</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.396167</td>\n",
       "      <td>0.453457</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.119309</td>\n",
       "      <td>0.096931</td>\n",
       "      <td>-0.39375</td>\n",
       "      <td>0.057757</td>\n",
       "      <td>0.119117</td>\n",
       "      <td>0.177832</td>\n",
       "      <td>0.727841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.039625</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.028384</td>\n",
       "      <td>0.039023</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.155488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.016612</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.184932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate_positive_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.682150</td>\n",
       "      <td>0.190206</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate_negative_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.287934</td>\n",
       "      <td>0.156156</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.104542</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.306244</td>\n",
       "      <td>0.358755</td>\n",
       "      <td>0.411428</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.095446</td>\n",
       "      <td>0.071315</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.756728</td>\n",
       "      <td>0.247786</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>-0.259524</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.328383</td>\n",
       "      <td>-0.253333</td>\n",
       "      <td>-0.186905</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>-0.521944</td>\n",
       "      <td>0.290290</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>-0.107500</td>\n",
       "      <td>0.095373</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_subjectivity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.324247</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.071425</td>\n",
       "      <td>0.265450</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.341843</td>\n",
       "      <td>0.188791</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.156064</td>\n",
       "      <td>0.226294</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shares</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>3395.380184</td>\n",
       "      <td>11626.950749</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>946.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>2800.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 count           mean            std      min  \\\n",
       "timedelta                      39644.0     354.530471     214.163767  8.00000   \n",
       "n_tokens_title                 39644.0      10.398749       2.114037  2.00000   \n",
       "n_tokens_content               39644.0     546.514731     471.107508  0.00000   \n",
       "num_hrefs                      39644.0      10.883690      11.332017  0.00000   \n",
       "num_self_hrefs                 39644.0       3.293638       3.855141  0.00000   \n",
       "num_imgs                       39644.0       4.544143       8.309434  0.00000   \n",
       "num_videos                     39644.0       1.249874       4.107855  0.00000   \n",
       "average_token_length           39644.0       4.548239       0.844406  0.00000   \n",
       "num_keywords                   39644.0       7.223767       1.909130  1.00000   \n",
       "data_channel_is_lifestyle      39644.0       0.052946       0.223929  0.00000   \n",
       "data_channel_is_entertainment  39644.0       0.178009       0.382525  0.00000   \n",
       "data_channel_is_bus            39644.0       0.157855       0.364610  0.00000   \n",
       "data_channel_is_socmed         39644.0       0.058597       0.234871  0.00000   \n",
       "data_channel_is_tech           39644.0       0.185299       0.388545  0.00000   \n",
       "data_channel_is_world          39644.0       0.212567       0.409129  0.00000   \n",
       "kw_min_min                     39644.0      26.106801      69.633215 -1.00000   \n",
       "kw_max_min                     39644.0    1153.951682    3857.990877  0.00000   \n",
       "kw_avg_min                     39644.0     312.366967     620.783887 -1.00000   \n",
       "kw_min_max                     39644.0   13612.354102   57986.029357  0.00000   \n",
       "kw_max_max                     39644.0  752324.066694  214502.129573  0.00000   \n",
       "kw_avg_max                     39644.0  259281.938083  135102.247285  0.00000   \n",
       "kw_min_avg                     39644.0    1117.146610    1137.456951 -1.00000   \n",
       "kw_max_avg                     39644.0    5657.211151    6098.871957  0.00000   \n",
       "kw_avg_avg                     39644.0    3135.858639    1318.150397  0.00000   \n",
       "self_reference_min_shares      39644.0    3998.755396   19738.670516  0.00000   \n",
       "self_reference_max_shares      39644.0   10329.212662   41027.576613  0.00000   \n",
       "self_reference_avg_sharess     39644.0    6401.697580   24211.332231  0.00000   \n",
       "weekday_is_monday              39644.0       0.168020       0.373889  0.00000   \n",
       "weekday_is_tuesday             39644.0       0.186409       0.389441  0.00000   \n",
       "weekday_is_wednesday           39644.0       0.187544       0.390353  0.00000   \n",
       "weekday_is_thursday            39644.0       0.183306       0.386922  0.00000   \n",
       "weekday_is_friday              39644.0       0.143805       0.350896  0.00000   \n",
       "weekday_is_saturday            39644.0       0.061876       0.240933  0.00000   \n",
       "weekday_is_sunday              39644.0       0.069039       0.253524  0.00000   \n",
       "is_weekend                     39644.0       0.130915       0.337312  0.00000   \n",
       "LDA_00                         39644.0       0.184599       0.262975  0.00000   \n",
       "LDA_01                         39644.0       0.141256       0.219707  0.00000   \n",
       "LDA_02                         39644.0       0.216321       0.282145  0.00000   \n",
       "LDA_03                         39644.0       0.223770       0.295191  0.00000   \n",
       "LDA_04                         39644.0       0.234029       0.289183  0.00000   \n",
       "global_subjectivity            39644.0       0.443370       0.116685  0.00000   \n",
       "global_sentiment_polarity      39644.0       0.119309       0.096931 -0.39375   \n",
       "global_rate_positive_words     39644.0       0.039625       0.017429  0.00000   \n",
       "global_rate_negative_words     39644.0       0.016612       0.010828  0.00000   \n",
       "rate_positive_words            39644.0       0.682150       0.190206  0.00000   \n",
       "rate_negative_words            39644.0       0.287934       0.156156  0.00000   \n",
       "avg_positive_polarity          39644.0       0.353825       0.104542  0.00000   \n",
       "min_positive_polarity          39644.0       0.095446       0.071315  0.00000   \n",
       "max_positive_polarity          39644.0       0.756728       0.247786  0.00000   \n",
       "avg_negative_polarity          39644.0      -0.259524       0.127726 -1.00000   \n",
       "min_negative_polarity          39644.0      -0.521944       0.290290 -1.00000   \n",
       "max_negative_polarity          39644.0      -0.107500       0.095373 -1.00000   \n",
       "title_subjectivity             39644.0       0.282353       0.324247  0.00000   \n",
       "title_sentiment_polarity       39644.0       0.071425       0.265450 -1.00000   \n",
       "abs_title_subjectivity         39644.0       0.341843       0.188791  0.00000   \n",
       "abs_title_sentiment_polarity   39644.0       0.156064       0.226294  0.00000   \n",
       "shares                         39644.0    3395.380184   11626.950749  1.00000   \n",
       "\n",
       "                                         25%            50%            75%  \\\n",
       "timedelta                         164.000000     339.000000     542.000000   \n",
       "n_tokens_title                      9.000000      10.000000      12.000000   \n",
       "n_tokens_content                  246.000000     409.000000     716.000000   \n",
       "num_hrefs                           4.000000       8.000000      14.000000   \n",
       "num_self_hrefs                      1.000000       3.000000       4.000000   \n",
       "num_imgs                            1.000000       1.000000       4.000000   \n",
       "num_videos                          0.000000       0.000000       1.000000   \n",
       "average_token_length                4.478404       4.664082       4.854839   \n",
       "num_keywords                        6.000000       7.000000       9.000000   \n",
       "data_channel_is_lifestyle           0.000000       0.000000       0.000000   \n",
       "data_channel_is_entertainment       0.000000       0.000000       0.000000   \n",
       "data_channel_is_bus                 0.000000       0.000000       0.000000   \n",
       "data_channel_is_socmed              0.000000       0.000000       0.000000   \n",
       "data_channel_is_tech                0.000000       0.000000       0.000000   \n",
       "data_channel_is_world               0.000000       0.000000       0.000000   \n",
       "kw_min_min                         -1.000000      -1.000000       4.000000   \n",
       "kw_max_min                        445.000000     660.000000    1000.000000   \n",
       "kw_avg_min                        141.750000     235.500000     357.000000   \n",
       "kw_min_max                          0.000000    1400.000000    7900.000000   \n",
       "kw_max_max                     843300.000000  843300.000000  843300.000000   \n",
       "kw_avg_max                     172846.875000  244572.222223  330980.000000   \n",
       "kw_min_avg                          0.000000    1023.635611    2056.781032   \n",
       "kw_max_avg                       3562.101631    4355.688836    6019.953968   \n",
       "kw_avg_avg                       2382.448566    2870.074878    3600.229564   \n",
       "self_reference_min_shares         639.000000    1200.000000    2600.000000   \n",
       "self_reference_max_shares        1100.000000    2800.000000    8000.000000   \n",
       "self_reference_avg_sharess        981.187500    2200.000000    5200.000000   \n",
       "weekday_is_monday                   0.000000       0.000000       0.000000   \n",
       "weekday_is_tuesday                  0.000000       0.000000       0.000000   \n",
       "weekday_is_wednesday                0.000000       0.000000       0.000000   \n",
       "weekday_is_thursday                 0.000000       0.000000       0.000000   \n",
       "weekday_is_friday                   0.000000       0.000000       0.000000   \n",
       "weekday_is_saturday                 0.000000       0.000000       0.000000   \n",
       "weekday_is_sunday                   0.000000       0.000000       0.000000   \n",
       "is_weekend                          0.000000       0.000000       0.000000   \n",
       "LDA_00                              0.025051       0.033387       0.240958   \n",
       "LDA_01                              0.025012       0.033345       0.150831   \n",
       "LDA_02                              0.028571       0.040004       0.334218   \n",
       "LDA_03                              0.028571       0.040001       0.375763   \n",
       "LDA_04                              0.028574       0.040727       0.399986   \n",
       "global_subjectivity                 0.396167       0.453457       0.508333   \n",
       "global_sentiment_polarity           0.057757       0.119117       0.177832   \n",
       "global_rate_positive_words          0.028384       0.039023       0.050279   \n",
       "global_rate_negative_words          0.009615       0.015337       0.021739   \n",
       "rate_positive_words                 0.600000       0.710526       0.800000   \n",
       "rate_negative_words                 0.185185       0.280000       0.384615   \n",
       "avg_positive_polarity               0.306244       0.358755       0.411428   \n",
       "min_positive_polarity               0.050000       0.100000       0.100000   \n",
       "max_positive_polarity               0.600000       0.800000       1.000000   \n",
       "avg_negative_polarity              -0.328383      -0.253333      -0.186905   \n",
       "min_negative_polarity              -0.700000      -0.500000      -0.300000   \n",
       "max_negative_polarity              -0.125000      -0.100000      -0.050000   \n",
       "title_subjectivity                  0.000000       0.150000       0.500000   \n",
       "title_sentiment_polarity            0.000000       0.000000       0.150000   \n",
       "abs_title_subjectivity              0.166667       0.500000       0.500000   \n",
       "abs_title_sentiment_polarity        0.000000       0.000000       0.250000   \n",
       "shares                            946.000000    1400.000000    2800.000000   \n",
       "\n",
       "                                         max  \n",
       "timedelta                         731.000000  \n",
       "n_tokens_title                     23.000000  \n",
       "n_tokens_content                 8474.000000  \n",
       "num_hrefs                         304.000000  \n",
       "num_self_hrefs                    116.000000  \n",
       "num_imgs                          128.000000  \n",
       "num_videos                         91.000000  \n",
       "average_token_length                8.041534  \n",
       "num_keywords                       10.000000  \n",
       "data_channel_is_lifestyle           1.000000  \n",
       "data_channel_is_entertainment       1.000000  \n",
       "data_channel_is_bus                 1.000000  \n",
       "data_channel_is_socmed              1.000000  \n",
       "data_channel_is_tech                1.000000  \n",
       "data_channel_is_world               1.000000  \n",
       "kw_min_min                        377.000000  \n",
       "kw_max_min                     298400.000000  \n",
       "kw_avg_min                      42827.857143  \n",
       "kw_min_max                     843300.000000  \n",
       "kw_max_max                     843300.000000  \n",
       "kw_avg_max                     843300.000000  \n",
       "kw_min_avg                       3613.039820  \n",
       "kw_max_avg                     298400.000000  \n",
       "kw_avg_avg                      43567.659946  \n",
       "self_reference_min_shares      843300.000000  \n",
       "self_reference_max_shares      843300.000000  \n",
       "self_reference_avg_sharess     843300.000000  \n",
       "weekday_is_monday                   1.000000  \n",
       "weekday_is_tuesday                  1.000000  \n",
       "weekday_is_wednesday                1.000000  \n",
       "weekday_is_thursday                 1.000000  \n",
       "weekday_is_friday                   1.000000  \n",
       "weekday_is_saturday                 1.000000  \n",
       "weekday_is_sunday                   1.000000  \n",
       "is_weekend                          1.000000  \n",
       "LDA_00                              0.926994  \n",
       "LDA_01                              0.925947  \n",
       "LDA_02                              0.919999  \n",
       "LDA_03                              0.926534  \n",
       "LDA_04                              0.927191  \n",
       "global_subjectivity                 1.000000  \n",
       "global_sentiment_polarity           0.727841  \n",
       "global_rate_positive_words          0.155488  \n",
       "global_rate_negative_words          0.184932  \n",
       "rate_positive_words                 1.000000  \n",
       "rate_negative_words                 1.000000  \n",
       "avg_positive_polarity               1.000000  \n",
       "min_positive_polarity               1.000000  \n",
       "max_positive_polarity               1.000000  \n",
       "avg_negative_polarity               0.000000  \n",
       "min_negative_polarity               0.000000  \n",
       "max_negative_polarity               0.000000  \n",
       "title_subjectivity                  1.000000  \n",
       "title_sentiment_polarity            1.000000  \n",
       "abs_title_subjectivity              0.500000  \n",
       "abs_title_sentiment_polarity        1.000000  \n",
       "shares                         843300.000000  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# ... creating data_channel categorical variable\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "df['data_channel'] = 'Others'\n",
    "\n",
    "condition = df['data_channel_is_lifestyle'] == 1\n",
    "df.loc[condition, 'data_channel'] = 'Lifestyle'\n",
    "\n",
    "condition = df['data_channel_is_entertainment'] == 1\n",
    "df.loc[condition, 'data_channel'] = 'Entertainment'\n",
    "\n",
    "condition = df['data_channel_is_bus'] == 1\n",
    "df.loc[condition, 'data_channel'] = 'Business'\n",
    "\n",
    "condition = df['data_channel_is_socmed'] == 1\n",
    "df.loc[condition, 'data_channel'] = 'Social Media'\n",
    "\n",
    "condition = df['data_channel_is_tech'] == 1\n",
    "df.loc[condition, 'data_channel'] = 'Technology'\n",
    "\n",
    "condition = df['data_channel_is_world'] == 1\n",
    "df.loc[condition, 'data_channel'] = 'World'\n",
    "\n",
    "del df['data_channel_is_lifestyle']\n",
    "del df['data_channel_is_entertainment']\n",
    "del df['data_channel_is_bus']\n",
    "del df['data_channel_is_socmed']\n",
    "del df['data_channel_is_tech']\n",
    "del df['data_channel_is_world']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "World            8427\n",
       "Technology       7346\n",
       "Entertainment    7057\n",
       "Business         6258\n",
       "Others           6134\n",
       "Social Media     2323\n",
       "Lifestyle        2099\n",
       "Name: data_channel, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.data_channel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# ... integer value of categorical values for multinomial NB classification\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "df['data_channel_n'] = 0\n",
    "\n",
    "condition = df['data_channel'] == 'Business'\n",
    "df.loc[condition, 'data_channel_n'] = 1\n",
    "\n",
    "condition = df['data_channel'] == 'Entertainment'\n",
    "df.loc[condition, 'data_channel_n'] = 2\n",
    "\n",
    "condition = df['data_channel'] == 'Lifestyle'\n",
    "df.loc[condition, 'data_channel_n'] = 3\n",
    "\n",
    "condition = df['data_channel'] == 'Others'\n",
    "df.loc[condition, 'data_channel_n'] = 4\n",
    "\n",
    "condition = df['data_channel'] == 'Social Media'\n",
    "df.loc[condition, 'data_channel_n'] = 5\n",
    "\n",
    "condition = df['data_channel'] == 'Technology'\n",
    "df.loc[condition, 'data_channel_n'] = 6\n",
    "\n",
    "condition = df['data_channel'] == 'World'\n",
    "df.loc[condition, 'data_channel_n'] = 7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    8427\n",
       "6    7346\n",
       "2    7057\n",
       "1    6258\n",
       "4    6134\n",
       "5    2323\n",
       "3    2099\n",
       "Name: data_channel_n, dtype: int64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.data_channel_n.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# ...  shares is task 1 dependent variable\n",
    "# ...  we are excluding it from this model as per business model this value is not available\n",
    "# ...  during data_channel prediction\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "del df['shares'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# ...  convert the data type to Integer\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "to_int = ['timedelta','n_tokens_title', 'n_tokens_content',\n",
    "    'num_hrefs','num_self_hrefs', 'num_imgs', 'num_videos', 'num_keywords',\n",
    "    'weekday_is_monday',\n",
    "    'weekday_is_tuesday',\n",
    "    'weekday_is_wednesday',\n",
    "    'weekday_is_thursday',\n",
    "    'weekday_is_friday',\n",
    "    'weekday_is_saturday',\n",
    "    'weekday_is_sunday',\n",
    "    'is_weekend',\n",
    "    'data_channel_n']\n",
    "    \n",
    "\n",
    "df[to_int] = df[to_int ].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>...</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>data_channel</th>\n",
       "      <th>data_channel_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [timedelta, n_tokens_title, n_tokens_content, num_hrefs, num_self_hrefs, num_imgs, num_videos, average_token_length, num_keywords, kw_min_min, kw_max_min, kw_avg_min, kw_min_max, kw_max_max, kw_avg_max, kw_min_avg, kw_max_avg, kw_avg_avg, self_reference_min_shares, self_reference_max_shares, self_reference_avg_sharess, weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday, weekday_is_saturday, weekday_is_sunday, is_weekend, LDA_00, LDA_01, LDA_02, LDA_03, LDA_04, global_subjectivity, global_sentiment_polarity, global_rate_positive_words, global_rate_negative_words, rate_positive_words, rate_negative_words, avg_positive_polarity, min_positive_polarity, max_positive_polarity, avg_negative_polarity, min_negative_polarity, max_negative_polarity, title_subjectivity, title_sentiment_polarity, abs_title_subjectivity, abs_title_sentiment_polarity, data_channel, data_channel_n]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 52 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> min_value < 0 adjusted :  kw_min_min -1.0\n",
      "--> min_value < 0 adjusted :  kw_avg_min -1.0\n",
      "--> min_value < 0 adjusted :  kw_min_avg -1.0\n",
      "--> min_value < 0 adjusted :  global_sentiment_polarity -0.39375\n",
      "--> min_value < 0 adjusted :  avg_negative_polarity -1.0\n",
      "--> min_value < 0 adjusted :  min_negative_polarity -1.0\n",
      "--> min_value < 0 adjusted :  max_negative_polarity -1.0\n",
      "--> min_value < 0 adjusted :  title_sentiment_polarity -1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>timedelta</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>354.530471</td>\n",
       "      <td>214.163767</td>\n",
       "      <td>8.0</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>542.000000</td>\n",
       "      <td>731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_tokens_title</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>10.398749</td>\n",
       "      <td>2.114037</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_tokens_content</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>546.514731</td>\n",
       "      <td>471.107508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>716.000000</td>\n",
       "      <td>8474.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_hrefs</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>10.883690</td>\n",
       "      <td>11.332017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>304.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>3.293638</td>\n",
       "      <td>3.855141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>116.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_imgs</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>4.544143</td>\n",
       "      <td>8.309434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_videos</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>1.249874</td>\n",
       "      <td>4.107855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_token_length</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>4.548239</td>\n",
       "      <td>0.844406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.478404</td>\n",
       "      <td>4.664082</td>\n",
       "      <td>4.854839</td>\n",
       "      <td>8.041534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_keywords</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>7.223767</td>\n",
       "      <td>1.909130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_min</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>27.106801</td>\n",
       "      <td>69.633215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>378.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_max_min</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>1153.951682</td>\n",
       "      <td>3857.990877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>445.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>298400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_avg_min</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>313.366967</td>\n",
       "      <td>620.783887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.750000</td>\n",
       "      <td>236.500000</td>\n",
       "      <td>358.000000</td>\n",
       "      <td>42828.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_max</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>13612.354102</td>\n",
       "      <td>57986.029357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>7900.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_max_max</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>752324.066694</td>\n",
       "      <td>214502.129573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_avg_max</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>259281.938083</td>\n",
       "      <td>135102.247285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172846.875000</td>\n",
       "      <td>244572.222223</td>\n",
       "      <td>330980.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_avg</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>1118.146610</td>\n",
       "      <td>1137.456951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1024.635611</td>\n",
       "      <td>2057.781032</td>\n",
       "      <td>3614.039820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_max_avg</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>5657.211151</td>\n",
       "      <td>6098.871957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3562.101631</td>\n",
       "      <td>4355.688836</td>\n",
       "      <td>6019.953968</td>\n",
       "      <td>298400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>3135.858639</td>\n",
       "      <td>1318.150397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2382.448566</td>\n",
       "      <td>2870.074878</td>\n",
       "      <td>3600.229564</td>\n",
       "      <td>43567.659946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>3998.755396</td>\n",
       "      <td>19738.670516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>639.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>2600.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>10329.212662</td>\n",
       "      <td>41027.576613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>2800.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>6401.697580</td>\n",
       "      <td>24211.332231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>981.187500</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>5200.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.168020</td>\n",
       "      <td>0.373889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.186409</td>\n",
       "      <td>0.389441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.187544</td>\n",
       "      <td>0.390353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.183306</td>\n",
       "      <td>0.386922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.143805</td>\n",
       "      <td>0.350896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.061876</td>\n",
       "      <td>0.240933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.069039</td>\n",
       "      <td>0.253524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_weekend</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.130915</td>\n",
       "      <td>0.337312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_00</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.184599</td>\n",
       "      <td>0.262975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025051</td>\n",
       "      <td>0.033387</td>\n",
       "      <td>0.240958</td>\n",
       "      <td>0.926994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_01</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.141256</td>\n",
       "      <td>0.219707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025012</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>0.150831</td>\n",
       "      <td>0.925947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_02</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.216321</td>\n",
       "      <td>0.282145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.334218</td>\n",
       "      <td>0.919999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_03</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.223770</td>\n",
       "      <td>0.295191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.375763</td>\n",
       "      <td>0.926534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_04</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.234029</td>\n",
       "      <td>0.289183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.040727</td>\n",
       "      <td>0.399986</td>\n",
       "      <td>0.927191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_subjectivity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.443370</td>\n",
       "      <td>0.116685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396167</td>\n",
       "      <td>0.453457</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.513059</td>\n",
       "      <td>0.096931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451507</td>\n",
       "      <td>0.512867</td>\n",
       "      <td>0.571582</td>\n",
       "      <td>1.121591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.039625</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028384</td>\n",
       "      <td>0.039023</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.155488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.016612</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.184932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate_positive_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.682150</td>\n",
       "      <td>0.190206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate_negative_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.287934</td>\n",
       "      <td>0.156156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.104542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306244</td>\n",
       "      <td>0.358755</td>\n",
       "      <td>0.411428</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.095446</td>\n",
       "      <td>0.071315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.756728</td>\n",
       "      <td>0.247786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.671617</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.813095</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.478056</td>\n",
       "      <td>0.290290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.095373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_subjectivity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.324247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>1.071425</td>\n",
       "      <td>0.265450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.341843</td>\n",
       "      <td>0.188791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.156064</td>\n",
       "      <td>0.226294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_n</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>4.184366</td>\n",
       "      <td>2.205607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                count           mean            std  min  \\\n",
       "timedelta                     39644.0     354.530471     214.163767  8.0   \n",
       "n_tokens_title                39644.0      10.398749       2.114037  2.0   \n",
       "n_tokens_content              39644.0     546.514731     471.107508  0.0   \n",
       "num_hrefs                     39644.0      10.883690      11.332017  0.0   \n",
       "num_self_hrefs                39644.0       3.293638       3.855141  0.0   \n",
       "num_imgs                      39644.0       4.544143       8.309434  0.0   \n",
       "num_videos                    39644.0       1.249874       4.107855  0.0   \n",
       "average_token_length          39644.0       4.548239       0.844406  0.0   \n",
       "num_keywords                  39644.0       7.223767       1.909130  1.0   \n",
       "kw_min_min                    39644.0      27.106801      69.633215  0.0   \n",
       "kw_max_min                    39644.0    1153.951682    3857.990877  0.0   \n",
       "kw_avg_min                    39644.0     313.366967     620.783887  0.0   \n",
       "kw_min_max                    39644.0   13612.354102   57986.029357  0.0   \n",
       "kw_max_max                    39644.0  752324.066694  214502.129573  0.0   \n",
       "kw_avg_max                    39644.0  259281.938083  135102.247285  0.0   \n",
       "kw_min_avg                    39644.0    1118.146610    1137.456951  0.0   \n",
       "kw_max_avg                    39644.0    5657.211151    6098.871957  0.0   \n",
       "kw_avg_avg                    39644.0    3135.858639    1318.150397  0.0   \n",
       "self_reference_min_shares     39644.0    3998.755396   19738.670516  0.0   \n",
       "self_reference_max_shares     39644.0   10329.212662   41027.576613  0.0   \n",
       "self_reference_avg_sharess    39644.0    6401.697580   24211.332231  0.0   \n",
       "weekday_is_monday             39644.0       0.168020       0.373889  0.0   \n",
       "weekday_is_tuesday            39644.0       0.186409       0.389441  0.0   \n",
       "weekday_is_wednesday          39644.0       0.187544       0.390353  0.0   \n",
       "weekday_is_thursday           39644.0       0.183306       0.386922  0.0   \n",
       "weekday_is_friday             39644.0       0.143805       0.350896  0.0   \n",
       "weekday_is_saturday           39644.0       0.061876       0.240933  0.0   \n",
       "weekday_is_sunday             39644.0       0.069039       0.253524  0.0   \n",
       "is_weekend                    39644.0       0.130915       0.337312  0.0   \n",
       "LDA_00                        39644.0       0.184599       0.262975  0.0   \n",
       "LDA_01                        39644.0       0.141256       0.219707  0.0   \n",
       "LDA_02                        39644.0       0.216321       0.282145  0.0   \n",
       "LDA_03                        39644.0       0.223770       0.295191  0.0   \n",
       "LDA_04                        39644.0       0.234029       0.289183  0.0   \n",
       "global_subjectivity           39644.0       0.443370       0.116685  0.0   \n",
       "global_sentiment_polarity     39644.0       0.513059       0.096931  0.0   \n",
       "global_rate_positive_words    39644.0       0.039625       0.017429  0.0   \n",
       "global_rate_negative_words    39644.0       0.016612       0.010828  0.0   \n",
       "rate_positive_words           39644.0       0.682150       0.190206  0.0   \n",
       "rate_negative_words           39644.0       0.287934       0.156156  0.0   \n",
       "avg_positive_polarity         39644.0       0.353825       0.104542  0.0   \n",
       "min_positive_polarity         39644.0       0.095446       0.071315  0.0   \n",
       "max_positive_polarity         39644.0       0.756728       0.247786  0.0   \n",
       "avg_negative_polarity         39644.0       0.740476       0.127726  0.0   \n",
       "min_negative_polarity         39644.0       0.478056       0.290290  0.0   \n",
       "max_negative_polarity         39644.0       0.892500       0.095373  0.0   \n",
       "title_subjectivity            39644.0       0.282353       0.324247  0.0   \n",
       "title_sentiment_polarity      39644.0       1.071425       0.265450  0.0   \n",
       "abs_title_subjectivity        39644.0       0.341843       0.188791  0.0   \n",
       "abs_title_sentiment_polarity  39644.0       0.156064       0.226294  0.0   \n",
       "data_channel_n                39644.0       4.184366       2.205607  1.0   \n",
       "\n",
       "                                        25%            50%            75%  \\\n",
       "timedelta                        164.000000     339.000000     542.000000   \n",
       "n_tokens_title                     9.000000      10.000000      12.000000   \n",
       "n_tokens_content                 246.000000     409.000000     716.000000   \n",
       "num_hrefs                          4.000000       8.000000      14.000000   \n",
       "num_self_hrefs                     1.000000       3.000000       4.000000   \n",
       "num_imgs                           1.000000       1.000000       4.000000   \n",
       "num_videos                         0.000000       0.000000       1.000000   \n",
       "average_token_length               4.478404       4.664082       4.854839   \n",
       "num_keywords                       6.000000       7.000000       9.000000   \n",
       "kw_min_min                         0.000000       0.000000       5.000000   \n",
       "kw_max_min                       445.000000     660.000000    1000.000000   \n",
       "kw_avg_min                       142.750000     236.500000     358.000000   \n",
       "kw_min_max                         0.000000    1400.000000    7900.000000   \n",
       "kw_max_max                    843300.000000  843300.000000  843300.000000   \n",
       "kw_avg_max                    172846.875000  244572.222223  330980.000000   \n",
       "kw_min_avg                         1.000000    1024.635611    2057.781032   \n",
       "kw_max_avg                      3562.101631    4355.688836    6019.953968   \n",
       "kw_avg_avg                      2382.448566    2870.074878    3600.229564   \n",
       "self_reference_min_shares        639.000000    1200.000000    2600.000000   \n",
       "self_reference_max_shares       1100.000000    2800.000000    8000.000000   \n",
       "self_reference_avg_sharess       981.187500    2200.000000    5200.000000   \n",
       "weekday_is_monday                  0.000000       0.000000       0.000000   \n",
       "weekday_is_tuesday                 0.000000       0.000000       0.000000   \n",
       "weekday_is_wednesday               0.000000       0.000000       0.000000   \n",
       "weekday_is_thursday                0.000000       0.000000       0.000000   \n",
       "weekday_is_friday                  0.000000       0.000000       0.000000   \n",
       "weekday_is_saturday                0.000000       0.000000       0.000000   \n",
       "weekday_is_sunday                  0.000000       0.000000       0.000000   \n",
       "is_weekend                         0.000000       0.000000       0.000000   \n",
       "LDA_00                             0.025051       0.033387       0.240958   \n",
       "LDA_01                             0.025012       0.033345       0.150831   \n",
       "LDA_02                             0.028571       0.040004       0.334218   \n",
       "LDA_03                             0.028571       0.040001       0.375763   \n",
       "LDA_04                             0.028574       0.040727       0.399986   \n",
       "global_subjectivity                0.396167       0.453457       0.508333   \n",
       "global_sentiment_polarity          0.451507       0.512867       0.571582   \n",
       "global_rate_positive_words         0.028384       0.039023       0.050279   \n",
       "global_rate_negative_words         0.009615       0.015337       0.021739   \n",
       "rate_positive_words                0.600000       0.710526       0.800000   \n",
       "rate_negative_words                0.185185       0.280000       0.384615   \n",
       "avg_positive_polarity              0.306244       0.358755       0.411428   \n",
       "min_positive_polarity              0.050000       0.100000       0.100000   \n",
       "max_positive_polarity              0.600000       0.800000       1.000000   \n",
       "avg_negative_polarity              0.671617       0.746667       0.813095   \n",
       "min_negative_polarity              0.300000       0.500000       0.700000   \n",
       "max_negative_polarity              0.875000       0.900000       0.950000   \n",
       "title_subjectivity                 0.000000       0.150000       0.500000   \n",
       "title_sentiment_polarity           1.000000       1.000000       1.150000   \n",
       "abs_title_subjectivity             0.166667       0.500000       0.500000   \n",
       "abs_title_sentiment_polarity       0.000000       0.000000       0.250000   \n",
       "data_channel_n                     2.000000       4.000000       6.000000   \n",
       "\n",
       "                                        max  \n",
       "timedelta                        731.000000  \n",
       "n_tokens_title                    23.000000  \n",
       "n_tokens_content                8474.000000  \n",
       "num_hrefs                        304.000000  \n",
       "num_self_hrefs                   116.000000  \n",
       "num_imgs                         128.000000  \n",
       "num_videos                        91.000000  \n",
       "average_token_length               8.041534  \n",
       "num_keywords                      10.000000  \n",
       "kw_min_min                       378.000000  \n",
       "kw_max_min                    298400.000000  \n",
       "kw_avg_min                     42828.857143  \n",
       "kw_min_max                    843300.000000  \n",
       "kw_max_max                    843300.000000  \n",
       "kw_avg_max                    843300.000000  \n",
       "kw_min_avg                      3614.039820  \n",
       "kw_max_avg                    298400.000000  \n",
       "kw_avg_avg                     43567.659946  \n",
       "self_reference_min_shares     843300.000000  \n",
       "self_reference_max_shares     843300.000000  \n",
       "self_reference_avg_sharess    843300.000000  \n",
       "weekday_is_monday                  1.000000  \n",
       "weekday_is_tuesday                 1.000000  \n",
       "weekday_is_wednesday               1.000000  \n",
       "weekday_is_thursday                1.000000  \n",
       "weekday_is_friday                  1.000000  \n",
       "weekday_is_saturday                1.000000  \n",
       "weekday_is_sunday                  1.000000  \n",
       "is_weekend                         1.000000  \n",
       "LDA_00                             0.926994  \n",
       "LDA_01                             0.925947  \n",
       "LDA_02                             0.919999  \n",
       "LDA_03                             0.926534  \n",
       "LDA_04                             0.927191  \n",
       "global_subjectivity                1.000000  \n",
       "global_sentiment_polarity          1.121591  \n",
       "global_rate_positive_words         0.155488  \n",
       "global_rate_negative_words         0.184932  \n",
       "rate_positive_words                1.000000  \n",
       "rate_negative_words                1.000000  \n",
       "avg_positive_polarity              1.000000  \n",
       "min_positive_polarity              1.000000  \n",
       "max_positive_polarity              1.000000  \n",
       "avg_negative_polarity              1.000000  \n",
       "min_negative_polarity              1.000000  \n",
       "max_negative_polarity              1.000000  \n",
       "title_subjectivity                 1.000000  \n",
       "title_sentiment_polarity           2.000000  \n",
       "abs_title_subjectivity             0.500000  \n",
       "abs_title_sentiment_polarity       1.000000  \n",
       "data_channel_n                     7.000000  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# ...  for all columns with negative values, add +1 to all values in the column\n",
    "# ...  - the only columns with negative values are polarity / sentiment measures\n",
    "# ...  - adding a constant to all values does not modify distributions\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "df_numeric = df.select_dtypes(['number'])\n",
    "numeric_col_names = df_numeric.columns.values.tolist()\n",
    "\n",
    "# ... store min value for each column\n",
    "\n",
    "df_mins = df.min()\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# ...  loop on each column, test for min < 0, add constant as applicable\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "for column in numeric_col_names :\n",
    "    if df_mins[column] < 0 :\n",
    "        df[column] = df[column] - df_mins[column]\n",
    "        print('--> min_value < 0 adjusted : ', column, df_mins[column])\n",
    "        \n",
    "        \n",
    "df.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens_content 2.94542193879 ln_n_tokens_content\n",
      "num_hrefs 4.0134948282 ln_num_hrefs\n",
      "num_self_hrefs 5.17275110576 ln_num_self_hrefs\n",
      "num_imgs 3.94659584465 ln_num_imgs\n",
      "num_videos 7.0195327863 ln_num_videos\n",
      "kw_min_min 2.37494728018 ln_kw_min_min\n",
      "kw_max_min 35.3284337312 ln_kw_max_min\n",
      "kw_avg_min 31.3061081027 ln_kw_avg_min\n",
      "kw_min_max 10.3863716348 ln_kw_min_max\n",
      "kw_max_avg 16.4116695554 ln_kw_max_avg\n",
      "kw_avg_avg 5.76017729162 ln_kw_avg_avg\n",
      "self_reference_min_shares 26.2643641603 ln_self_reference_min_shares\n",
      "self_reference_max_shares 13.8708490494 ln_self_reference_max_shares\n",
      "self_reference_avg_sharess 17.9140933777 ln_self_reference_avg_sharess\n",
      "weekday_is_monday 1.77590824423 ln_weekday_is_monday\n",
      "weekday_is_tuesday 1.61054706191 ln_weekday_is_tuesday\n",
      "weekday_is_wednesday 1.60097097689 ln_weekday_is_wednesday\n",
      "weekday_is_thursday 1.6370700483 ln_weekday_is_thursday\n",
      "weekday_is_friday 2.03030483518 ln_weekday_is_friday\n",
      "weekday_is_saturday 3.63708575997 ln_weekday_is_saturday\n",
      "weekday_is_sunday 3.3999273763 ln_weekday_is_sunday\n",
      "is_weekend 2.18850033431 ln_is_weekend\n",
      "LDA_00 1.5674632332 ln_LDA_00\n",
      "LDA_01 2.08672182342 ln_LDA_01\n",
      "LDA_02 1.31169490203 ln_LDA_02\n",
      "LDA_03 1.23871598638 ln_LDA_03\n",
      "LDA_04 1.17312947598 ln_LDA_04\n",
      "global_rate_negative_words 1.49191730919 ln_global_rate_negative_words\n",
      "min_positive_polarity 3.04046773746 ln_min_positive_polarity\n",
      "abs_title_sentiment_polarity 1.70419343991 ln_abs_title_sentiment_polarity\n",
      "['n_tokens_content', 'num_hrefs', 'num_self_hrefs', 'num_imgs', 'num_videos', 'kw_min_min', 'kw_max_min', 'kw_avg_min', 'kw_min_max', 'kw_max_avg', 'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares', 'self_reference_avg_sharess', 'weekday_is_monday', 'weekday_is_tuesday', 'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday', 'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_rate_negative_words', 'min_positive_polarity', 'abs_title_sentiment_polarity']\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Number of current columns in dataset : 69\n"
     ]
    }
   ],
   "source": [
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# ...  ln() transform right skewed distribution variables (skewness > 1)\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "df_numeric = df.select_dtypes(['number'])\n",
    "\n",
    "numeric_col_names = df_numeric.columns.values.tolist()\n",
    "\n",
    "# ... store min value for each column\n",
    "\n",
    "df_mins = df.min()\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# ...  loop on each column, test for skewness, create new column if conditions met\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "columns_to_drop = []\n",
    "\n",
    "for column in numeric_col_names:\n",
    "    sk = df[column].skew()\n",
    "    \n",
    "    if(sk > 1):\n",
    "        new_col_name = 'ln_' + column\n",
    "        print (column, sk, new_col_name)\n",
    "        \n",
    "        if df_mins[column] > 0:\n",
    "            df[new_col_name] = np.log(df[column])\n",
    "            columns_to_drop.append(column)\n",
    "            \n",
    "        elif df_mins[column] == 0:\n",
    "            df_tmp = df[column] + 1\n",
    "            df[new_col_name] = np.log(df_tmp)\n",
    "            columns_to_drop.append(column)\n",
    "            \n",
    "        else:\n",
    "            print('--> Ln() transform not completed -- skew > 1, but min value < 0 :', column, '!!')\n",
    "            \n",
    "            \n",
    "# ... delete tmp data\n",
    "\n",
    "del df_tmp\n",
    "del df_mins\n",
    "del df_numeric\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# ...  based on inspection, a few of these are just not valid ranges in ln() space\n",
    "# ...  -- just delete these few back out of the data set\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "print (columns_to_drop)\n",
    "\n",
    "del df['ln_LDA_00']\n",
    "del df['ln_LDA_01']\n",
    "del df['ln_LDA_02']\n",
    "del df['ln_LDA_03']\n",
    "del df['ln_LDA_04']\n",
    "columns_to_drop.remove('LDA_00')\n",
    "columns_to_drop.remove('LDA_01')\n",
    "columns_to_drop.remove('LDA_02')\n",
    "columns_to_drop.remove('LDA_03')\n",
    "columns_to_drop.remove('LDA_04')\n",
    "\n",
    "# ...  these are binary indicators ... so no need to ln-transform\n",
    "\n",
    "del df['ln_weekday_is_monday']\n",
    "del df['ln_weekday_is_tuesday']\n",
    "del df['ln_weekday_is_wednesday']\n",
    "del df['ln_weekday_is_thursday']\n",
    "del df['ln_weekday_is_friday']\n",
    "del df['ln_weekday_is_saturday']\n",
    "del df['ln_weekday_is_sunday']\n",
    "del df['ln_is_weekend']\n",
    "columns_to_drop.remove('is_weekend')\n",
    "columns_to_drop.remove('weekday_is_monday')\n",
    "columns_to_drop.remove('weekday_is_tuesday')\n",
    "columns_to_drop.remove('weekday_is_wednesday')\n",
    "columns_to_drop.remove('weekday_is_thursday')\n",
    "columns_to_drop.remove('weekday_is_friday')\n",
    "columns_to_drop.remove('weekday_is_saturday')\n",
    "columns_to_drop.remove('weekday_is_sunday')\n",
    "\n",
    "#columns_to_drop.remove('data_channel')\n",
    "\n",
    "print ('\\n-----------------------------------\\n')\n",
    "print ('Number of current columns in dataset :', len(df.columns))\n",
    "\n",
    "df.drop(columns_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "#df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #TODO: EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timedelta', 'n_tokens_title', 'average_token_length', 'num_keywords',\n",
       "       'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'weekday_is_monday',\n",
       "       'weekday_is_tuesday', 'weekday_is_wednesday', 'weekday_is_thursday',\n",
       "       'weekday_is_friday', 'weekday_is_saturday', 'weekday_is_sunday',\n",
       "       'is_weekend', 'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04',\n",
       "       'global_subjectivity', 'global_sentiment_polarity',\n",
       "       'global_rate_positive_words', 'rate_positive_words',\n",
       "       'rate_negative_words', 'avg_positive_polarity', 'max_positive_polarity',\n",
       "       'avg_negative_polarity', 'min_negative_polarity',\n",
       "       'max_negative_polarity', 'title_subjectivity',\n",
       "       'title_sentiment_polarity', 'abs_title_subjectivity', 'data_channel',\n",
       "       'data_channel_n', 'ln_n_tokens_content', 'ln_num_hrefs',\n",
       "       'ln_num_self_hrefs', 'ln_num_imgs', 'ln_num_videos', 'ln_kw_min_min',\n",
       "       'ln_kw_max_min', 'ln_kw_avg_min', 'ln_kw_min_max', 'ln_kw_max_avg',\n",
       "       'ln_kw_avg_avg', 'ln_self_reference_min_shares',\n",
       "       'ln_self_reference_max_shares', 'ln_self_reference_avg_sharess',\n",
       "       'ln_global_rate_negative_words', 'ln_min_positive_polarity',\n",
       "       'ln_abs_title_sentiment_polarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>timedelta</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>354.530471</td>\n",
       "      <td>214.163767</td>\n",
       "      <td>8.0</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>542.000000</td>\n",
       "      <td>731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_tokens_title</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>10.398749</td>\n",
       "      <td>2.114037</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_token_length</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>4.548239</td>\n",
       "      <td>0.844406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.478404</td>\n",
       "      <td>4.664082</td>\n",
       "      <td>4.854839</td>\n",
       "      <td>8.041534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_keywords</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>7.223767</td>\n",
       "      <td>1.909130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_max_max</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>752324.066694</td>\n",
       "      <td>214502.129573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_avg_max</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>259281.938083</td>\n",
       "      <td>135102.247285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172846.875000</td>\n",
       "      <td>244572.222223</td>\n",
       "      <td>330980.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_avg</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>1118.146610</td>\n",
       "      <td>1137.456951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1024.635611</td>\n",
       "      <td>2057.781032</td>\n",
       "      <td>3614.039820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.168020</td>\n",
       "      <td>0.373889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.186409</td>\n",
       "      <td>0.389441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.187544</td>\n",
       "      <td>0.390353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.183306</td>\n",
       "      <td>0.386922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.143805</td>\n",
       "      <td>0.350896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.061876</td>\n",
       "      <td>0.240933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.069039</td>\n",
       "      <td>0.253524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_weekend</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.130915</td>\n",
       "      <td>0.337312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_00</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.184599</td>\n",
       "      <td>0.262975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025051</td>\n",
       "      <td>0.033387</td>\n",
       "      <td>0.240958</td>\n",
       "      <td>0.926994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_01</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.141256</td>\n",
       "      <td>0.219707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025012</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>0.150831</td>\n",
       "      <td>0.925947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_02</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.216321</td>\n",
       "      <td>0.282145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.334218</td>\n",
       "      <td>0.919999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_03</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.223770</td>\n",
       "      <td>0.295191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.375763</td>\n",
       "      <td>0.926534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_04</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.234029</td>\n",
       "      <td>0.289183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.040727</td>\n",
       "      <td>0.399986</td>\n",
       "      <td>0.927191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_subjectivity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.443370</td>\n",
       "      <td>0.116685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396167</td>\n",
       "      <td>0.453457</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.513059</td>\n",
       "      <td>0.096931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451507</td>\n",
       "      <td>0.512867</td>\n",
       "      <td>0.571582</td>\n",
       "      <td>1.121591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.039625</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028384</td>\n",
       "      <td>0.039023</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.155488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate_positive_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.682150</td>\n",
       "      <td>0.190206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate_negative_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.287934</td>\n",
       "      <td>0.156156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.104542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306244</td>\n",
       "      <td>0.358755</td>\n",
       "      <td>0.411428</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.756728</td>\n",
       "      <td>0.247786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.671617</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.813095</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.478056</td>\n",
       "      <td>0.290290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.095373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_subjectivity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.324247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>1.071425</td>\n",
       "      <td>0.265450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.341843</td>\n",
       "      <td>0.188791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_n</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>4.184366</td>\n",
       "      <td>2.205607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_n_tokens_content</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>5.889971</td>\n",
       "      <td>1.255442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.509388</td>\n",
       "      <td>6.016157</td>\n",
       "      <td>6.575076</td>\n",
       "      <td>9.044876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_num_hrefs</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>2.156564</td>\n",
       "      <td>0.809445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>5.720312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_num_self_hrefs</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>1.208878</td>\n",
       "      <td>0.692698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>4.762174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_num_imgs</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>1.116427</td>\n",
       "      <td>0.973755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>4.859812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_num_videos</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.400420</td>\n",
       "      <td>0.680486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>4.521789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_kw_min_min</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>1.174410</td>\n",
       "      <td>1.733030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>5.937536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_kw_max_min</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>6.393888</td>\n",
       "      <td>1.311168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.100319</td>\n",
       "      <td>6.493754</td>\n",
       "      <td>6.908755</td>\n",
       "      <td>12.606193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_kw_avg_min</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>5.302209</td>\n",
       "      <td>1.132463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.968076</td>\n",
       "      <td>5.470168</td>\n",
       "      <td>5.883322</td>\n",
       "      <td>10.664991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_kw_min_max</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>5.045209</td>\n",
       "      <td>4.521016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.244942</td>\n",
       "      <td>8.974745</td>\n",
       "      <td>13.645079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_kw_max_avg</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>8.482750</td>\n",
       "      <td>0.582051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.178387</td>\n",
       "      <td>8.379468</td>\n",
       "      <td>8.703001</td>\n",
       "      <td>12.606193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_kw_avg_avg</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>7.976327</td>\n",
       "      <td>0.489467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.776304</td>\n",
       "      <td>7.962442</td>\n",
       "      <td>8.189031</td>\n",
       "      <td>10.682093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_self_reference_min_shares</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>6.195185</td>\n",
       "      <td>3.076913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.461468</td>\n",
       "      <td>7.090910</td>\n",
       "      <td>7.863651</td>\n",
       "      <td>13.645079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_self_reference_max_shares</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>6.917477</td>\n",
       "      <td>3.432430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.003974</td>\n",
       "      <td>7.937732</td>\n",
       "      <td>8.987322</td>\n",
       "      <td>13.645079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_self_reference_avg_sharess</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>6.667697</td>\n",
       "      <td>3.280186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.889782</td>\n",
       "      <td>7.696667</td>\n",
       "      <td>8.556606</td>\n",
       "      <td>13.645079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_global_rate_negative_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.016419</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>0.015221</td>\n",
       "      <td>0.021506</td>\n",
       "      <td>0.169685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_min_positive_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.089255</td>\n",
       "      <td>0.060260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048790</td>\n",
       "      <td>0.095310</td>\n",
       "      <td>0.095310</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_abs_title_sentiment_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.128709</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223144</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   count           mean            std  min  \\\n",
       "timedelta                        39644.0     354.530471     214.163767  8.0   \n",
       "n_tokens_title                   39644.0      10.398749       2.114037  2.0   \n",
       "average_token_length             39644.0       4.548239       0.844406  0.0   \n",
       "num_keywords                     39644.0       7.223767       1.909130  1.0   \n",
       "kw_max_max                       39644.0  752324.066694  214502.129573  0.0   \n",
       "kw_avg_max                       39644.0  259281.938083  135102.247285  0.0   \n",
       "kw_min_avg                       39644.0    1118.146610    1137.456951  0.0   \n",
       "weekday_is_monday                39644.0       0.168020       0.373889  0.0   \n",
       "weekday_is_tuesday               39644.0       0.186409       0.389441  0.0   \n",
       "weekday_is_wednesday             39644.0       0.187544       0.390353  0.0   \n",
       "weekday_is_thursday              39644.0       0.183306       0.386922  0.0   \n",
       "weekday_is_friday                39644.0       0.143805       0.350896  0.0   \n",
       "weekday_is_saturday              39644.0       0.061876       0.240933  0.0   \n",
       "weekday_is_sunday                39644.0       0.069039       0.253524  0.0   \n",
       "is_weekend                       39644.0       0.130915       0.337312  0.0   \n",
       "LDA_00                           39644.0       0.184599       0.262975  0.0   \n",
       "LDA_01                           39644.0       0.141256       0.219707  0.0   \n",
       "LDA_02                           39644.0       0.216321       0.282145  0.0   \n",
       "LDA_03                           39644.0       0.223770       0.295191  0.0   \n",
       "LDA_04                           39644.0       0.234029       0.289183  0.0   \n",
       "global_subjectivity              39644.0       0.443370       0.116685  0.0   \n",
       "global_sentiment_polarity        39644.0       0.513059       0.096931  0.0   \n",
       "global_rate_positive_words       39644.0       0.039625       0.017429  0.0   \n",
       "rate_positive_words              39644.0       0.682150       0.190206  0.0   \n",
       "rate_negative_words              39644.0       0.287934       0.156156  0.0   \n",
       "avg_positive_polarity            39644.0       0.353825       0.104542  0.0   \n",
       "max_positive_polarity            39644.0       0.756728       0.247786  0.0   \n",
       "avg_negative_polarity            39644.0       0.740476       0.127726  0.0   \n",
       "min_negative_polarity            39644.0       0.478056       0.290290  0.0   \n",
       "max_negative_polarity            39644.0       0.892500       0.095373  0.0   \n",
       "title_subjectivity               39644.0       0.282353       0.324247  0.0   \n",
       "title_sentiment_polarity         39644.0       1.071425       0.265450  0.0   \n",
       "abs_title_subjectivity           39644.0       0.341843       0.188791  0.0   \n",
       "data_channel_n                   39644.0       4.184366       2.205607  1.0   \n",
       "ln_n_tokens_content              39644.0       5.889971       1.255442  0.0   \n",
       "ln_num_hrefs                     39644.0       2.156564       0.809445  0.0   \n",
       "ln_num_self_hrefs                39644.0       1.208878       0.692698  0.0   \n",
       "ln_num_imgs                      39644.0       1.116427       0.973755  0.0   \n",
       "ln_num_videos                    39644.0       0.400420       0.680486  0.0   \n",
       "ln_kw_min_min                    39644.0       1.174410       1.733030  0.0   \n",
       "ln_kw_max_min                    39644.0       6.393888       1.311168  0.0   \n",
       "ln_kw_avg_min                    39644.0       5.302209       1.132463  0.0   \n",
       "ln_kw_min_max                    39644.0       5.045209       4.521016  0.0   \n",
       "ln_kw_max_avg                    39644.0       8.482750       0.582051  0.0   \n",
       "ln_kw_avg_avg                    39644.0       7.976327       0.489467  0.0   \n",
       "ln_self_reference_min_shares     39644.0       6.195185       3.076913  0.0   \n",
       "ln_self_reference_max_shares     39644.0       6.917477       3.432430  0.0   \n",
       "ln_self_reference_avg_sharess    39644.0       6.667697       3.280186  0.0   \n",
       "ln_global_rate_negative_words    39644.0       0.016419       0.010571  0.0   \n",
       "ln_min_positive_polarity         39644.0       0.089255       0.060260  0.0   \n",
       "ln_abs_title_sentiment_polarity  39644.0       0.128709       0.173844  0.0   \n",
       "\n",
       "                                           25%            50%            75%  \\\n",
       "timedelta                           164.000000     339.000000     542.000000   \n",
       "n_tokens_title                        9.000000      10.000000      12.000000   \n",
       "average_token_length                  4.478404       4.664082       4.854839   \n",
       "num_keywords                          6.000000       7.000000       9.000000   \n",
       "kw_max_max                       843300.000000  843300.000000  843300.000000   \n",
       "kw_avg_max                       172846.875000  244572.222223  330980.000000   \n",
       "kw_min_avg                            1.000000    1024.635611    2057.781032   \n",
       "weekday_is_monday                     0.000000       0.000000       0.000000   \n",
       "weekday_is_tuesday                    0.000000       0.000000       0.000000   \n",
       "weekday_is_wednesday                  0.000000       0.000000       0.000000   \n",
       "weekday_is_thursday                   0.000000       0.000000       0.000000   \n",
       "weekday_is_friday                     0.000000       0.000000       0.000000   \n",
       "weekday_is_saturday                   0.000000       0.000000       0.000000   \n",
       "weekday_is_sunday                     0.000000       0.000000       0.000000   \n",
       "is_weekend                            0.000000       0.000000       0.000000   \n",
       "LDA_00                                0.025051       0.033387       0.240958   \n",
       "LDA_01                                0.025012       0.033345       0.150831   \n",
       "LDA_02                                0.028571       0.040004       0.334218   \n",
       "LDA_03                                0.028571       0.040001       0.375763   \n",
       "LDA_04                                0.028574       0.040727       0.399986   \n",
       "global_subjectivity                   0.396167       0.453457       0.508333   \n",
       "global_sentiment_polarity             0.451507       0.512867       0.571582   \n",
       "global_rate_positive_words            0.028384       0.039023       0.050279   \n",
       "rate_positive_words                   0.600000       0.710526       0.800000   \n",
       "rate_negative_words                   0.185185       0.280000       0.384615   \n",
       "avg_positive_polarity                 0.306244       0.358755       0.411428   \n",
       "max_positive_polarity                 0.600000       0.800000       1.000000   \n",
       "avg_negative_polarity                 0.671617       0.746667       0.813095   \n",
       "min_negative_polarity                 0.300000       0.500000       0.700000   \n",
       "max_negative_polarity                 0.875000       0.900000       0.950000   \n",
       "title_subjectivity                    0.000000       0.150000       0.500000   \n",
       "title_sentiment_polarity              1.000000       1.000000       1.150000   \n",
       "abs_title_subjectivity                0.166667       0.500000       0.500000   \n",
       "data_channel_n                        2.000000       4.000000       6.000000   \n",
       "ln_n_tokens_content                   5.509388       6.016157       6.575076   \n",
       "ln_num_hrefs                          1.609438       2.197225       2.708050   \n",
       "ln_num_self_hrefs                     0.693147       1.386294       1.609438   \n",
       "ln_num_imgs                           0.693147       0.693147       1.609438   \n",
       "ln_num_videos                         0.000000       0.000000       0.693147   \n",
       "ln_kw_min_min                         0.000000       0.000000       1.791759   \n",
       "ln_kw_max_min                         6.100319       6.493754       6.908755   \n",
       "ln_kw_avg_min                         4.968076       5.470168       5.883322   \n",
       "ln_kw_min_max                         0.000000       7.244942       8.974745   \n",
       "ln_kw_max_avg                         8.178387       8.379468       8.703001   \n",
       "ln_kw_avg_avg                         7.776304       7.962442       8.189031   \n",
       "ln_self_reference_min_shares          6.461468       7.090910       7.863651   \n",
       "ln_self_reference_max_shares          7.003974       7.937732       8.987322   \n",
       "ln_self_reference_avg_sharess         6.889782       7.696667       8.556606   \n",
       "ln_global_rate_negative_words         0.009569       0.015221       0.021506   \n",
       "ln_min_positive_polarity              0.048790       0.095310       0.095310   \n",
       "ln_abs_title_sentiment_polarity       0.000000       0.000000       0.223144   \n",
       "\n",
       "                                           max  \n",
       "timedelta                           731.000000  \n",
       "n_tokens_title                       23.000000  \n",
       "average_token_length                  8.041534  \n",
       "num_keywords                         10.000000  \n",
       "kw_max_max                       843300.000000  \n",
       "kw_avg_max                       843300.000000  \n",
       "kw_min_avg                         3614.039820  \n",
       "weekday_is_monday                     1.000000  \n",
       "weekday_is_tuesday                    1.000000  \n",
       "weekday_is_wednesday                  1.000000  \n",
       "weekday_is_thursday                   1.000000  \n",
       "weekday_is_friday                     1.000000  \n",
       "weekday_is_saturday                   1.000000  \n",
       "weekday_is_sunday                     1.000000  \n",
       "is_weekend                            1.000000  \n",
       "LDA_00                                0.926994  \n",
       "LDA_01                                0.925947  \n",
       "LDA_02                                0.919999  \n",
       "LDA_03                                0.926534  \n",
       "LDA_04                                0.927191  \n",
       "global_subjectivity                   1.000000  \n",
       "global_sentiment_polarity             1.121591  \n",
       "global_rate_positive_words            0.155488  \n",
       "rate_positive_words                   1.000000  \n",
       "rate_negative_words                   1.000000  \n",
       "avg_positive_polarity                 1.000000  \n",
       "max_positive_polarity                 1.000000  \n",
       "avg_negative_polarity                 1.000000  \n",
       "min_negative_polarity                 1.000000  \n",
       "max_negative_polarity                 1.000000  \n",
       "title_subjectivity                    1.000000  \n",
       "title_sentiment_polarity              2.000000  \n",
       "abs_title_subjectivity                0.500000  \n",
       "data_channel_n                        7.000000  \n",
       "ln_n_tokens_content                   9.044876  \n",
       "ln_num_hrefs                          5.720312  \n",
       "ln_num_self_hrefs                     4.762174  \n",
       "ln_num_imgs                           4.859812  \n",
       "ln_num_videos                         4.521789  \n",
       "ln_kw_min_min                         5.937536  \n",
       "ln_kw_max_min                        12.606193  \n",
       "ln_kw_avg_min                        10.664991  \n",
       "ln_kw_min_max                        13.645079  \n",
       "ln_kw_max_avg                        12.606193  \n",
       "ln_kw_avg_avg                        10.682093  \n",
       "ln_self_reference_min_shares         13.645079  \n",
       "ln_self_reference_max_shares         13.645079  \n",
       "ln_self_reference_avg_sharess        13.645079  \n",
       "ln_global_rate_negative_words         0.169685  \n",
       "ln_min_positive_polarity              0.693147  \n",
       "ln_abs_title_sentiment_polarity       0.693147  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "World            8427\n",
       "Technology       7346\n",
       "Entertainment    7057\n",
       "Business         6258\n",
       "Others           6134\n",
       "Social Media     2323\n",
       "Lifestyle        2099\n",
       "Name: data_channel, dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "df.columns\n",
    "\n",
    "df.describe().T\n",
    "\n",
    "df.data_channel.value_counts()\n",
    "\n",
    "data_dir = '../data/'\n",
    "data_file = 'mashable_clean_dataset_for_lab_02_task_02.csv'\n",
    "\n",
    "file_2_write = data_dir + data_file\n",
    "\n",
    "df.to_csv(file_2_write, index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=10, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# ...  copy data frame to classification working data frame\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# ... data set with text categorical target values \n",
    "\n",
    "df_data_channel = df.copy()\n",
    "del df_data_channel['data_channel_n']\n",
    "\n",
    "# ... data set with integer categorical target values \n",
    "\n",
    "df_data_channel_n = df.copy()\n",
    "del df_data_channel_n['data_channel']\n",
    "del df_data_channel_n['kw_max_max']\n",
    "del df_data_channel_n['kw_avg_max']\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# ...  separate X and y matrices \n",
    "# ...\n",
    "# ...  convert to numpy matrices by calling 'values' on the pandas data frames\n",
    "# ...  they are now simple matrices for compatibility with scikit-learn\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "if 'data_channel' in df_data_channel:\n",
    "    y = df_data_channel['data_channel'].values         # set 'data_channel' as dependent\n",
    "    del df_data_channel['data_channel']                # remove from dataset\n",
    "    X = df_data_channel.values                         # use everything else for independent EVs\n",
    "\n",
    "if 'data_channel_n' in df_data_channel_n:\n",
    "    y_n = df_data_channel_n['data_channel_n'].values    # set 'data_channel' as dependent\n",
    "    del df_data_channel_n['data_channel_n']             # remove from dataset\n",
    "    X_n = df_data_channel_n.values                      # use everything else for independent EVs\n",
    "\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# ...  dataframe in which to record results of model metrics\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "results_table_labels = ['n_features', 'n_estimate', 'process_time', 'accuracy', 'recall', 'precision', 'f1_score']\n",
    "df_results = pd.DataFrame(columns = results_table_labels)\n",
    "\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# ...  setup cross-validation in sklearn\n",
    "# ...\n",
    "# ...  split into training and test sets\n",
    "# ....  --> 10 folds\n",
    "# ...   --> 80% / 20% training / test\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "num_cv_iterations = 10\n",
    "\n",
    "num_instances = len(y)\n",
    "\n",
    "cv_object = ShuffleSplit(n_splits = num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# ...  run through the cross validation loop and set the training and testing\n",
    "# ...  variable for one single iteration\n",
    "# ...\n",
    "# ...  --> this method is memory-user, but easier to follow what is being done \n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X, y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]    \n",
    "    X_test  = X[test_indices]\n",
    "    y_test  = y[test_indices]\n",
    "    \n",
    "    \n",
    "for train_indices, test_indices in cv_object.split(X_n, y_n): \n",
    "    X_train_n = X_n[train_indices]\n",
    "    y_train_n = y_n[train_indices]    \n",
    "    X_test_n  = X_n[test_indices]\n",
    "    y_test_n  = y_n[test_indices]\n",
    "\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# ... scale attributes by the training set\n",
    "# ... - normalize features based on mean & stdev of each column\n",
    "# ... - do not use the testing data\n",
    "# ... - use what was last stored in the variables: X_train, y_train, X_test, y_test\n",
    "# ... -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train)                        # scale for each column for (0,1) mean, std\n",
    "    \n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled  = scl_obj.transform(X_test) \n",
    "\n",
    "\n",
    "scl_obj.fit(X_train_n)                        # scale for each column for (0,1) mean, std\n",
    "    \n",
    "X_train_n_scaled = scl_obj.transform(X_train_n) # apply to training\n",
    "X_test_n_scaled  = scl_obj.transform(X_test_n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comparison_tbl = pd.DataFrame(columns = ['Model Name','Accuracy','Processing Time'])\n",
    "i_index=[]\n",
    "i_index = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 : Multinomial logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7600\n",
      "confusion matrix\n",
      " [[ 956   14   33   16  138   47   20]\n",
      " [  13 1093   25  176   58   16   39]\n",
      " [  36    2  211   14   30   94    8]\n",
      " [   6  130   35 1021   37    3   12]\n",
      " [  55   28   38   31  229   16   33]\n",
      " [  34   19  259    5   48 1088   72]\n",
      " [  18   35   47   32   75   56 1428]]\n",
      "process time 7.2125\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "\n",
    "#basic multiclass LR\n",
    "\n",
    "lr_model1 = LogisticRegression(class_weight='balanced', multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "lr_model1.fit(X_train_scaled, y_train)  # train object\n",
    "\n",
    "y_hat = lr_model1.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "\n",
    "accuracy = '{0:.4f}'.format(metrics.accuracy_score(y_test, y_hat))\n",
    "\n",
    "print(\"accuracy\",accuracy )\n",
    "print(\"confusion matrix\\n\", conf(y_test, y_hat))\n",
    "\n",
    "toc =  time.clock()\n",
    "exetime = '{0:.4f}'.format(toc-tic)\n",
    "print('process time',exetime)\n",
    "print(\"\\n\")\n",
    "\n",
    "raw_data = {\n",
    "    'Model Name':'Multinomial logistic regression',\n",
    "    'Accuracy':accuracy,\n",
    "    'Processing Time': exetime\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(raw_data,columns = ['Model Name','Accuracy','Processing Time'],index=[i_index+1])\n",
    "\n",
    "comparison_tbl = comparison_tbl.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.7630\n",
      "confusion matrix\n",
      " [[1011   24   45    7  142   37   23]\n",
      " [  15 1096   21  153   51   10   33]\n",
      " [  22    5  221   22   30   89   13]\n",
      " [   1  131   35 1013   27    9   14]\n",
      " [  82   34   23   35  267   26   33]\n",
      " [  38   16  263    4   58  983   65]\n",
      " [  16   56   35   25   62   49 1459]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 1  ====\n",
      "accuracy 0.7628\n",
      "confusion matrix\n",
      " [[ 973   16   50   15  127   47   19]\n",
      " [   8 1076   24  184   39   10   30]\n",
      " [  24    6  216   19   32   96   18]\n",
      " [   6  119   29 1004   33    5   14]\n",
      " [  68   31   45   34  242   20   34]\n",
      " [  31   18  264    1   51 1051   75]\n",
      " [  17   41   43   24   61   53 1486]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 2  ====\n",
      "accuracy 0.7653\n",
      "confusion matrix\n",
      " [[1009   18   49   15  121   49   19]\n",
      " [   9 1095   19  167   47   12   28]\n",
      " [  24    2  215   18   31  102   14]\n",
      " [   6  133   25 1034   27    7   19]\n",
      " [  74   30   35   33  233   13   35]\n",
      " [  34   20  250    3   46 1047   59]\n",
      " [  18   59   48   19   67   57 1435]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 3  ====\n",
      "accuracy 0.7599\n",
      "confusion matrix\n",
      " [[1011   13   44   17  145   48   16]\n",
      " [  20 1085   24  177   61   12   30]\n",
      " [  29    4  237   22   30   83   10]\n",
      " [   7  130   34  987   29    4   12]\n",
      " [  61   26   47   29  250   19   36]\n",
      " [  36   24  256    3   44 1008   60]\n",
      " [  16   51   26   26   74   69 1447]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 4  ====\n",
      "accuracy 0.7613\n",
      "confusion matrix\n",
      " [[1007   18   33   21  120   39   21]\n",
      " [  13 1142   29  176   55   13   25]\n",
      " [  30    3  250   20   32   91    5]\n",
      " [   3  132   29  982   36    6   17]\n",
      " [  73   26   36   27  256   18   33]\n",
      " [  34   23  273    3   51  988   75]\n",
      " [  16   40   53   15   72   58 1411]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 5  ====\n",
      "accuracy 0.7623\n",
      "confusion matrix\n",
      " [[1053   12   42   11  121   59   14]\n",
      " [  21 1093   30  175   63    6   30]\n",
      " [  27    9  225   19   36   81   11]\n",
      " [   5  109   42  998   29    8   17]\n",
      " [  63   28   39   28  265   18   34]\n",
      " [  45   18  266    3   51 1003   70]\n",
      " [  16   52   38   25   69   45 1407]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 6  ====\n",
      "accuracy 0.7626\n",
      "confusion matrix\n",
      " [[ 998   18   31   16  130   50   24]\n",
      " [   6 1047   25  187   46   17   30]\n",
      " [  24    6  233   12   28   98   12]\n",
      " [   8  119   42 1048   28    8   10]\n",
      " [  72   27   41   29  234   19   31]\n",
      " [  39   21  257    2   51 1018   57]\n",
      " [  17   42   35   27   75   65 1469]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 7  ====\n",
      "accuracy 0.7693\n",
      "confusion matrix\n",
      " [[ 977   12   40   10  115   52   18]\n",
      " [  11 1119   31  155   51   14   38]\n",
      " [  21    8  236   17   46   83   14]\n",
      " [   6  123   38 1058   24    6   22]\n",
      " [  61   30   55   26  236   19   39]\n",
      " [  33   17  240    2   41 1006   75]\n",
      " [  12   46   37   22   64   55 1468]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 8  ====\n",
      "accuracy 0.7590\n",
      "confusion matrix\n",
      " [[ 994    8   38   14  165   36   22]\n",
      " [   8 1031   24  179   51   12   28]\n",
      " [  29    9  229   24   35  102   15]\n",
      " [   3  137   42 1037   26    6   15]\n",
      " [  64   31   35   26  251   22   34]\n",
      " [  41   11  258    2   56 1025   61]\n",
      " [  18   34   32   26   70   62 1451]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 9  ====\n",
      "accuracy 0.7668\n",
      "confusion matrix\n",
      " [[ 993   15   48   18  140   52   19]\n",
      " [   7 1114   21  180   57   15   31]\n",
      " [  25    4  225   23   26   80   11]\n",
      " [   8  114   43 1000   33    4   18]\n",
      " [  67   36   33   28  251   16   33]\n",
      " [  35   13  233    3   42 1076   71]\n",
      " [  14   39   41   26   73   54 1421]]\n"
     ]
    }
   ],
   "source": [
    "num_cv_iterations = 10\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits = num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "cv_accuracy=[]\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X,y)):\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    scl_obj = StandardScaler()\n",
    "    scl_obj.fit(X_train)                        # scale for each column for (0,1) mean, std\n",
    "    \n",
    "    X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "    X_test_scaled = scl_obj.transform(X_test) \n",
    "    \n",
    "    lr_model1.fit(X_train_scaled, y_train)  # train object\n",
    "    y_hat = lr_model1.predict(X_test_scaled) # get test set precitions\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    accuracy = '{0:.4f}'.format(metrics.accuracy_score(y_test, y_hat))\n",
    "    print(\"accuracy\", accuracy)\n",
    "    print(\"confusion matrix\\n\", conf(y_test, y_hat))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.7630',\n",
       " '0.7628',\n",
       " '0.7653',\n",
       " '0.7599',\n",
       " '0.7613',\n",
       " '0.7623',\n",
       " '0.7626',\n",
       " '0.7693',\n",
       " '0.7590',\n",
       " '0.7668']"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744734518855\n",
      "process time 3.9995\n",
      "[[1015   28   39   22   75   62   44]\n",
      " [  31 1100   13  179   42   18   42]\n",
      " [  40   14  141   27   20  133   19]\n",
      " [  17  152   29  954   24    8   36]\n",
      " [  82   39   20   23  220   35   45]\n",
      " [  54   34  167   10   34 1087   87]\n",
      " [  40   51   27   36   47   79 1388]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "tic = time.clock()\n",
    "\n",
    "# train and fit\n",
    "DTclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "DTclassifier.fit(X_train, y_train)\n",
    "y_predDT = DTclassifier.predict(X_test)\n",
    "\n",
    "#accuracy\n",
    "acc = accuracy_score(y_test, y_predDT)\n",
    "print(acc)\n",
    "toc =  time.clock()\n",
    "exetime = '{0:.4f}'.format(toc-tic)\n",
    "print('process time',exetime)\n",
    "\n",
    "#used later in the code for comparison\n",
    "raw_data = {\n",
    "    'Model Name':'Decision Tree Classifier',\n",
    "    'Accuracy':accuracy,\n",
    "    'Processing Time': exetime\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(raw_data,columns = ['Model Name','Accuracy','Processing Time'],index=[i_index+1])\n",
    "comparison_tbl = comparison_tbl.append(df)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cmDT = confusion_matrix(y_test, y_predDT)\n",
    "print(cmDT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.808803127759\n",
      "process time 6.0634\n",
      "[[1140   20   11   11   17   52   34]\n",
      " [  25 1171    2  163    5   30   29]\n",
      " [  54   11  105   29   13  165   17]\n",
      " [  15  104   19 1055    3    7   17]\n",
      " [ 115   44   10   27  183   37   48]\n",
      " [  45   21   65    4    7 1272   59]\n",
      " [  39   40   11   30    8   53 1487]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "tic = time.clock()\n",
    "# train and test \n",
    "RFclf = RandomForestClassifier(criterion = 'entropy', max_depth=50, n_estimators=10, n_jobs=-1)\n",
    "RFclf.fit(X_train, y_train)\n",
    "y_predRF = RFclf.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "total_accuracyRF = mt.accuracy_score(y_test, y_predRF)\n",
    "print ('Accuracy', total_accuracyRF)\n",
    "toc =  time.clock()\n",
    "exetime = '{0:.4f}'.format(toc-tic)\n",
    "print('process time',exetime)\n",
    "\n",
    "#used later in the code for comparison\n",
    "raw_data = {\n",
    "    'Model Name':'Random Forest Classifier',\n",
    "    'Accuracy':total_accuracyRF,\n",
    "    'Processing Time': exetime\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(raw_data,columns = ['Model Name','Accuracy','Processing Time'],index=[i_index+1])\n",
    "comparison_tbl = comparison_tbl.append(df)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cmRF2 = confusion_matrix(y_test, y_predRF)\n",
    "print(cmRF2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 50 artists>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD3CAYAAADSftWOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nklSQw1uSCnJ4S1JB/w/9sV45zcRWWwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd48e8863c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (RFclf)\n",
    "\n",
    "plt.barh(range(len(RFclf.feature_importances_)), RFclf.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Processing Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial logistic regression</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>7.2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.7668</td>\n",
       "      <td>3.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.808803</td>\n",
       "      <td>6.0634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model Name  Accuracy Processing Time\n",
       "0  Multinomial logistic regression    0.7600          7.2125\n",
       "1         Decision Tree Classifier    0.7668          3.9995\n",
       "2         Random Forest Classifier  0.808803          6.0634"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_tbl = comparison_tbl.reset_index(drop=True)\n",
    "comparison_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3: Naive Bayes ***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " class counts\n",
      "[ 5037.  5643.  1672.  4849.  1886.  5919.  6709.]\n",
      "\n",
      " class prior prob (log)\n",
      "[-1.83997909 -1.72637392 -2.94276924 -1.87801726 -2.82233157 -1.67862224\n",
      " -1.55333985]\n",
      "\n",
      "\n",
      "\n",
      " feature counts\n",
      "[[  1.93435900e+06   5.18080000e+04   2.36253918e+04   3.26750000e+04\n",
      "    5.61222605e+06   9.23000000e+02   9.26000000e+02   1.02100000e+03\n",
      "    1.02300000e+03   6.69000000e+02   1.97000000e+02   2.78000000e+02\n",
      "    4.75000000e+02   3.29156037e+03   3.94207026e+02   4.10121965e+02\n",
      "    3.31728191e+02   6.09382447e+02   2.19493266e+03   2.66721446e+03\n",
      "    2.17825545e+02   3.71833793e+03   1.29966207e+03   1.77739333e+03\n",
      "    3.86465037e+03   3.81427361e+03   2.61185212e+03   4.49132456e+03\n",
      "    1.27174292e+03   5.44193094e+03   1.71007737e+03   3.03150155e+04\n",
      "    1.06759609e+04   5.60011914e+03   3.97740528e+03   1.09967265e+03\n",
      "    6.70959891e+03   3.19701297e+04   2.69426750e+04   2.64485552e+04\n",
      "    4.22691822e+04   3.98991442e+04   2.87068603e+04   3.21707003e+04\n",
      "    3.09912314e+04   7.34562464e+01   4.09717645e+02   5.91492434e+02]\n",
      " [  1.87945300e+06   6.20340000e+04   2.52936165e+04   3.89990000e+04\n",
      "    6.39883331e+06   1.07800000e+03   1.02300000e+03   1.03200000e+03\n",
      "    9.77000000e+02   7.78000000e+02   3.17000000e+02   4.38000000e+02\n",
      "    7.55000000e+02   3.71461392e+02   2.37433478e+03   5.15901183e+02\n",
      "    2.02204055e+03   3.58262090e+02   2.54919488e+03   2.85042877e+03\n",
      "    2.28844563e+02   3.76549883e+03   1.72150117e+03   2.06536988e+03\n",
      "    4.50670892e+03   3.98163114e+03   2.32214464e+03   5.01908321e+03\n",
      "    1.77120085e+03   6.00996192e+03   1.81615690e+03   3.37857323e+04\n",
      "    1.16810737e+04   7.39620671e+03   7.01930661e+03   3.85113976e+03\n",
      "    5.69181250e+03   3.57790904e+04   2.94642923e+04   2.96642730e+04\n",
      "    4.80358493e+04   4.51966449e+04   3.65196124e+04   4.15017058e+04\n",
      "    3.97629939e+04   1.06174186e+02   4.94674205e+02   7.98657427e+02]\n",
      " [  6.78323000e+05   1.63200000e+04   7.67554441e+03   1.37210000e+04\n",
      "    1.78410130e+06   2.66000000e+02   2.56000000e+02   3.19000000e+02\n",
      "    2.92000000e+02   2.29000000e+02   1.48000000e+02   1.62000000e+02\n",
      "    3.10000000e+02   3.06052465e+02   1.09078145e+02   1.30655075e+02\n",
      "    2.39359238e+02   8.86855077e+02   7.93109104e+02   9.12728601e+02\n",
      "    7.43217705e+01   1.20876600e+03   4.47234002e+02   6.39770319e+02\n",
      "    1.38396667e+03   1.23389953e+03   7.49826221e+02   1.50024876e+03\n",
      "    4.83839076e+02   1.85800351e+03   5.76621352e+02   1.02905002e+04\n",
      "    3.99777363e+03   1.70748371e+03   2.07272693e+03   3.58114544e+02\n",
      "    2.64034864e+03   1.10430014e+04   9.26154827e+03   6.97143696e+03\n",
      "    1.43666886e+04   1.34542040e+04   1.02410761e+04   1.09250988e+04\n",
      "    1.06910625e+04   2.71926791e+01   1.48245930e+02   2.35179932e+02]\n",
      " [  1.75207100e+06   5.00640000e+04   2.04078083e+04   3.62260000e+04\n",
      "    7.68834667e+06   7.32000000e+02   8.56000000e+02   8.47000000e+02\n",
      "    8.68000000e+02   7.80000000e+02   3.31000000e+02   4.35000000e+02\n",
      "    7.66000000e+02   2.88680530e+02   6.89809420e+02   2.76140426e+02\n",
      "    3.29094729e+03   3.03422339e+02   2.24086009e+03   2.47908343e+03\n",
      "    1.84930673e+02   2.94876795e+03   1.37623205e+03   1.76538185e+03\n",
      "    3.50841665e+03   3.48078770e+03   2.37263766e+03   4.23825514e+03\n",
      "    1.79335714e+03   5.26543241e+03   1.59707131e+03   2.45520743e+04\n",
      "    1.06995579e+04   5.54542626e+03   6.89963085e+03   3.44313129e+03\n",
      "    6.17292672e+03   3.16316864e+04   2.59834953e+04   2.88915659e+04\n",
      "    4.31491325e+04   4.05257330e+04   3.19245669e+04   3.51278510e+04\n",
      "    3.41277427e+04   8.65098769e+01   5.24679513e+02   8.34628645e+02]\n",
      " [  7.91724000e+05   1.81270000e+04   8.74110633e+03   1.24310000e+04\n",
      "    2.49348037e+06   2.74000000e+02   3.70000000e+02   3.36000000e+02\n",
      "    3.81000000e+02   2.69000000e+02   1.43000000e+02   1.13000000e+02\n",
      "    2.56000000e+02   7.30779686e+02   1.47796207e+02   3.69929104e+02\n",
      "    3.39203991e+02   2.98291012e+02   8.65719952e+02   1.01558515e+03\n",
      "    8.81740916e+01   1.40615893e+03   4.69841065e+02   6.71977539e+02\n",
      "    1.47226153e+03   1.40144407e+03   9.02319826e+02   1.67486813e+03\n",
      "    4.90044284e+02   2.06159807e+03   6.61628109e+02   1.14379172e+04\n",
      "    4.31178471e+03   2.68178338e+03   2.05414644e+03   6.94457808e+02\n",
      "    2.96423470e+03   1.21701013e+04   1.04465024e+04   1.00997805e+04\n",
      "    1.59719658e+04   1.51296753e+04   1.23071301e+04   1.41003803e+04\n",
      "    1.34851322e+04   2.92177764e+01   1.36206571e+02   2.31257427e+02]\n",
      " [  2.32271900e+06   6.02980000e+04   2.71375944e+04   4.60540000e+04\n",
      "    5.91027488e+06   1.00400000e+03   1.18000000e+03   1.14600000e+03\n",
      "    1.05600000e+03   8.05000000e+02   4.19000000e+02   3.09000000e+02\n",
      "    7.28000000e+02   4.36341807e+02   3.88756126e+02   6.54987723e+02\n",
      "    3.63278719e+02   4.07563563e+03   2.70492507e+03   3.19499038e+03\n",
      "    2.54593849e+02   4.42263316e+03   1.48136684e+03   2.11451622e+03\n",
      "    4.56860785e+03   4.56884199e+03   3.25703194e+03   5.31160380e+03\n",
      "    1.48594623e+03   6.40934672e+03   2.05027545e+03   3.58377554e+04\n",
      "    1.25739460e+04   8.66065303e+03   6.76792630e+03   1.40928624e+03\n",
      "    8.16120190e+03   3.87944314e+04   3.22700900e+04   2.69257942e+04\n",
      "    4.91938434e+04   4.65056399e+04   3.86138782e+04   4.38056301e+04\n",
      "    4.19289429e+04   8.47229677e+01   5.51245412e+02   6.52834126e+02]\n",
      " [  1.91886800e+06   7.10870000e+04   3.13977059e+04   4.88470000e+04\n",
      "    5.55459222e+06   1.06300000e+03   1.25200000e+03   1.26600000e+03\n",
      "    1.24100000e+03   1.03500000e+03   4.05000000e+02   4.47000000e+02\n",
      "    8.52000000e+02   4.48364993e+02   3.64623049e+02   4.49364736e+03\n",
      "    4.92434798e+02   9.09929804e+02   2.70480731e+03   3.15898787e+03\n",
      "    2.10270324e+02   4.18737129e+03   2.31762871e+03   2.17980839e+03\n",
      "    4.69885126e+03   5.01586051e+03   2.94965418e+03   6.07557773e+03\n",
      "    1.63296963e+03   6.90276538e+03   2.43118665e+03   4.06337652e+04\n",
      "    1.44104517e+04   6.70631515e+03   6.54259477e+03   1.86987012e+03\n",
      "    5.08571091e+03   4.13354107e+04   3.37977574e+04   3.08148153e+04\n",
      "    5.60216225e+04   5.22454325e+04   3.82375749e+04   4.17421925e+04\n",
      "    4.04849865e+04   1.12617415e+02   5.59128630e+02   7.19519088e+02]]\n",
      "\n",
      " feature prob (log)\n",
      "[[ -1.42206496  -5.04203288  -5.82723238  -5.5029559   -0.35689386\n",
      "   -9.06863997  -9.06539847  -8.96783527  -8.96588023  -9.39007433\n",
      "  -10.60908501 -10.26614026  -9.73193418  -7.79793127  -9.9179423\n",
      "   -9.87846212 -10.09002612  -9.48326632  -8.2029899   -8.00818725\n",
      "  -10.50907722  -7.67605108  -8.72672334  -8.41388643  -7.63746682\n",
      "   -7.65058438  -8.02915437  -7.48722647  -8.74842241  -7.29527907\n",
      "   -8.45247355  -5.57792062  -6.62150853  -7.26663034  -7.6087157\n",
      "   -8.89367527  -7.08590856  -5.52476346  -5.69584819  -5.71435742\n",
      "   -5.24551483  -5.30321682  -5.6324258   -5.51850957  -5.55586019\n",
      "  -11.58714038  -9.87944606  -9.51301394]\n",
      " [ -1.54740673  -4.95844458  -5.85555174  -5.42258168  -0.32227221\n",
      "   -9.01010864  -9.0624268   -9.05367613  -9.10838893  -9.33588756\n",
      "  -10.23184722  -9.90939919  -9.36585723 -10.07376521  -8.22100493\n",
      "   -9.74604688  -8.38154172 -10.10984642  -8.14997354  -8.03832313\n",
      "  -10.55649533  -7.75999744  -8.54236592  -8.36034994  -7.5803543\n",
      "   -7.70420063  -8.24322161  -7.47269681  -8.51392113  -7.29255853\n",
      "   -8.48887018  -5.56607513  -6.62808782  -7.08504087  -7.13733643\n",
      "   -7.73751455  -7.34693891  -5.50875172  -5.70293028  -5.69616622\n",
      "   -5.21417491  -5.27509834  -5.4882665   -5.3603847   -5.4031815\n",
      "  -11.31944319  -9.78797974  -9.30971518]\n",
      " [ -1.35288225  -5.08005468  -5.83433781  -5.25350692  -0.38583665\n",
      "   -9.19301393  -9.2311865   -9.01194159  -9.10008997  -9.34218327\n",
      "   -9.77631628  -9.68651238  -9.04046967  -9.05324396 -10.07907206\n",
      "   -9.90007715  -9.29812796  -7.99145406  -8.10304172  -7.96272899\n",
      "  -10.45849337  -7.68208035  -8.67494716  -8.31759151  -7.54683123\n",
      "   -7.66151769  -8.15908836  -7.46621003  -8.59644555  -7.25246671\n",
      "   -8.42134403  -5.54118898  -6.48651958  -7.33690104  -7.14315987\n",
      "   -8.89662118  -6.90121767  -5.47061988  -5.6465281   -5.93054251\n",
      "   -5.20752547  -5.27314136  -5.54600296  -5.481353    -5.50300566\n",
      "  -11.44120025  -9.7746671   -9.31566865]\n",
      " [ -1.73385454  -5.28908674  -6.18644232  -5.61260421  -0.25494773\n",
      "   -9.51301848  -9.35672626  -9.36728355  -9.34282106  -9.44958903\n",
      "  -10.30502921 -10.03252194  -9.46767738 -10.44138549  -9.5723002\n",
      "  -10.48563985  -8.01092963 -10.39174817  -8.39510299  -8.2941167\n",
      "  -10.8847903   -8.1206824   -8.88233318  -8.6334756   -7.94695908\n",
      "   -7.95486304  -8.33798525  -7.75802133  -8.61776209  -7.54105573\n",
      "   -8.73361143  -6.00157183  -6.83211303  -7.4892551   -7.27079607\n",
      "   -7.9657372   -7.38207385  -5.74821794  -5.94490888  -5.83882458\n",
      "   -5.43772342  -5.50044707  -5.73900175  -5.64338615  -5.67226898\n",
      "  -11.63841252  -9.84547245  -9.38197987]\n",
      " [ -1.47769944  -5.25445585  -5.98376239  -5.63163976  -0.3304784\n",
      "   -9.44289773  -9.14346677  -9.2395859   -9.11424822  -9.46124687\n",
      "  -10.08985553 -10.32347038  -9.51059275  -8.46418934 -10.0570912\n",
      "   -9.14365788  -9.23012342  -9.35825245  -8.29495291  -8.13546443\n",
      "  -10.56907829  -7.81034082  -8.90514824  -8.54795688  -7.76443488\n",
      "   -7.81369707  -8.25359216  -7.63558223  -8.86313452  -7.42794716\n",
      "   -8.56345492  -5.71489222  -6.69032975  -7.16505872  -7.43156645\n",
      "   -8.51509849  -7.06495737  -5.65284916  -5.8055506   -5.83930085\n",
      "   -5.3810159   -5.43518939  -5.64165352  -5.50564086  -5.55025164\n",
      "  -11.65123846 -10.13818122  -9.61182248]\n",
      " [ -1.33356387  -4.98474255  -5.7831012   -5.25422173  -0.39961028\n",
      "   -9.07907053  -8.91769653  -8.94690823  -9.02862336  -9.2997296\n",
      "   -9.95155863 -10.25524105  -9.40013961  -9.91109829 -10.02629212\n",
      "   -9.50567127 -10.09389406  -7.67878602  -8.08861423  -7.92216105\n",
      "  -10.44822369  -7.59709673  -8.69041804  -8.33475921  -7.56463068\n",
      "   -7.56457944  -7.90293475  -7.41397599  -8.68733356  -7.22614471\n",
      "   -8.3655963   -5.50502821  -6.55235165  -6.92515248  -7.17171559\n",
      "   -8.74026538  -6.98454409  -5.42575557  -5.60988628  -5.79093621\n",
      "   -5.18826926  -5.24446297  -5.43042042  -5.30427289  -5.34805787\n",
      "  -11.54069255  -9.67782081  -9.50895966]\n",
      " [ -1.43949772  -4.7350704   -5.55222227  -5.11027551  -0.37660848\n",
      "   -8.93695356  -8.77344827  -8.76233705  -8.78226596  -8.9636218\n",
      "   -9.90039107  -9.80195099  -9.15798468  -9.79890877 -10.00514135\n",
      "   -7.49610174  -9.7053535   -9.09227839  -8.00358863  -7.84842076\n",
      "  -10.55360576  -7.566677    -8.15801301  -8.21929332  -7.45145809\n",
      "   -7.38618461  -7.91696205  -7.19454728  -8.50797654  -7.06692198\n",
      "   -8.11019824  -5.29436496  -6.3309658   -7.0957902   -7.12050227\n",
      "   -8.37258532  -7.37235751  -5.27724522  -5.47856491  -5.57096091\n",
      "   -4.97323337  -5.04301734  -5.35514413  -5.26745256  -5.29803305\n",
      "  -11.17390743  -9.57857777  -9.32677232]]\n",
      "MultinomialNB Naïve Bayes Accuracy : 0.215033421617\n",
      "[[ 33  26  15 484  53 539  71]\n",
      " [ 21  34  10 626  48 557 118]\n",
      " [  1   5  10 156  13 220  22]\n",
      " [ 13  18  13 643  67 456  75]\n",
      " [  4   5   5 181  32 198  12]\n",
      " [ 22  21  15 528  72 689  80]\n",
      " [ 31  50   9 686  49 629 264]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf_mnb = MultinomialNB(alpha = 1.0, class_prior = None, fit_prior = True)\n",
    "\n",
    "clf_mnb.fit(X_train_n, y_train_n)\n",
    "\n",
    "print('\\n class counts') \n",
    "print (clf_mnb.class_count_)\n",
    "print('\\n class prior prob (log)')\n",
    "print (clf_mnb.class_log_prior_)\n",
    "\n",
    "print('\\n\\n\\n feature counts') \n",
    "print (clf_mnb.feature_count_)\n",
    "print('\\n feature prob (log)')\n",
    "print (clf_mnb.feature_log_prob_)\n",
    "\n",
    "y_hatm = clf_mnb.predict(X_test_n)\n",
    "    \n",
    "accm = mt.accuracy_score(y_test_n, y_hatm)\n",
    "    \n",
    "print('MultinomialNB Naïve Bayes Accuracy :', accm) \n",
    "\n",
    "# ... confusion matrix\n",
    "\n",
    "cm_nb = confusion_matrix(y_test_n, y_hatm)\n",
    "print(cm_nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'C': 100, 'tol': 0.001}\n",
      "-1.707 (+/-0.005) for {'C': 100, 'tol': 0.001}\n",
      "[-1.709344   -1.70980855 -1.6985925  -1.70435365 -1.71102994]\n",
      "-1.707 (+/-0.005) for {'C': 100, 'tol': 0.0001}\n",
      "[-1.709344   -1.70980855 -1.6985925  -1.70435365 -1.71102994]\n",
      "-1.707 (+/-0.005) for {'C': 1000, 'tol': 0.001}\n",
      "[-1.709344   -1.70980853 -1.6985925  -1.70435365 -1.7110587 ]\n",
      "-1.707 (+/-0.005) for {'C': 1000, 'tol': 0.0001}\n",
      "[-1.709344   -1.70980853 -1.6985925  -1.70435365 -1.7110587 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "params = {'C':[100, 1000], 'tol': [0.001, 0.0001]}\n",
    "log_reg = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "clf = GridSearchCV(log_reg, params, scoring='log_loss', refit='True', n_jobs=-1, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"best params: \" + str(clf.best_params_))\n",
    "for params, mean_score, scores in clf.grid_scores_:\n",
    "  print(\"%0.3f (+/-%0.03f) for %r\" % (mean_score, scores.std(), params))\n",
    "  print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO list\n",
    "EDA for data_channel predition\n",
    "\n",
    "calculating recall and precision from confusion matrix. generic function for all models. \n",
    "\n",
    "cross validation for all models.\n",
    "\n",
    "Naive Bayes is throwing import error of sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rubrik\n",
    "### 1\tData Preparation Part 1\t\n",
    "10\t\n",
    "Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.\n",
    "### 2\tData Preparation Part 2\n",
    "5\t\n",
    "Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "###  Modeling and Evaluation 1\t\n",
    "10\tChoose and explain your evaluation metrics that you will use (i.e., accuracy,precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "### \tModeling and Evaluation 2\t\n",
    "10\t\n",
    "Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time.\n",
    "\n",
    "### \tModeling and Evaluation 3\t\n",
    "20\t\n",
    "Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!\n",
    "\n",
    "### \tModeling and Evaluation 4\t\n",
    "10\t\n",
    "Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "\n",
    "### \tModeling and Evaluation 5\t\n",
    "10\t\n",
    "Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course.\n",
    "\n",
    "### \tModeling and Evaluation 6\t\n",
    "10\t\n",
    "Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.\n",
    "\n",
    "### \tDeployment\t\n",
    "5\t\n",
    "How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? \n",
    "\n",
    "### \tExceptional Work\t\n",
    "10\t\n",
    "You have free reign to provide additional analyses. One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
